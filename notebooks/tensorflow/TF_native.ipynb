{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6496458a-7825-4cf6-8ead-8e6b09164992",
   "metadata": {},
   "source": [
    "# Test of native TF/Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94da375a-f9b6-4bc6-ad7a-b3d7a5472e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 02:47:18.778864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-28 02:47:18.778951: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, SpatialDropout1D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42642912-3e58-4128-ba5b-2c1b50dc7339",
   "metadata": {},
   "source": [
    "## Global Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45677eac-554d-4bb2-8423-c969702277bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1919\n",
    "BATCH_SIZE = 128\n",
    "SEQUENCE_SIZE = 10\n",
    "EMBEDDING_SIZE = 30\n",
    "NUMBER_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa2dbc-0080-4764-8c34-5ca0d8fcd33a",
   "metadata": {},
   "source": [
    "## Setup Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a230793-f3f6-47f6-ab3c-e8aa71314a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reproducible data\n",
    "np.random.seed(13)\n",
    "\n",
    "#create artificial training data\n",
    "X = np.random.normal(size = (NUMBER_SAMPLES, SEQUENCE_SIZE, EMBEDDING_SIZE)).astype(np.float32)\n",
    "y = np.random.binomial(1, 0.3, size = NUMBER_SAMPLES).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f98e44-b0ed-43f2-abcb-12c06344093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (10000, 10, 30), y shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X shape {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be047f94-5617-4bd7-9394-6c24b2e44c1a",
   "metadata": {},
   "source": [
    "## Reproducibility Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b107d0-503b-4f7f-9b95-8e5874b0c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reproducible training\n",
    "def set_for_reproducibility():\n",
    "    # ensure clean setup of TF\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # set various RNG seed\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    # single-thread execution for reproducibility at the expense of run-time\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ead2c5-2332-413f-9397-5bcdd04f70a2",
   "metadata": {},
   "source": [
    "##  test original 3-d Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9237969-e60f-45ff-892f-1361595304de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reproducible training\n",
    "set_for_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc88acc0-220b-462a-a8c9-7c0401b05a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "#build and compile TF model\n",
    "\n",
    "\n",
    "def nn():\n",
    "    model_input = Input(shape = (SEQUENCE_SIZE, EMBEDDING_SIZE))\n",
    "    model_dropout1 = SpatialDropout1D(0.2)(model_input)\n",
    "    model_lstm = LSTM(100, dropout = 0.2, recurrent_dropout = 0.2)(model_dropout1)\n",
    "    model_dense1 = Dense(50, activation = 'tanh')(model_lstm)\n",
    "    model_bn1 = BatchNormalization()(model_dense1)\n",
    "    model_dropout2 = Dropout(0.2)(model_bn1)\n",
    "    model_output = Dense(1, activation = 'sigmoid')(model_dropout2)\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = [AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a01dd93-02ee-41ca-8560-1dc8f34e738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 02:47:21.801155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-28 02:47:21.801208: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-28 02:47:21.801244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dask-notebook-0): /proc/driver/nvidia/version does not exist\n",
      "2021-11-28 02:47:21.801502: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline model training\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 7s 42ms/step - loss: 0.7360 - auc: 0.4954\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.6593 - auc: 0.5064\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.6393 - auc: 0.5234\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.6348 - auc: 0.5230\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.6259 - auc: 0.5411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8ae03aa30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "model = nn()\n",
    "\n",
    "print('\\nBaseline model training')\n",
    "model.fit(X, y, epochs=5, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52212a-7d2d-4133-815b-3a08073bcfea",
   "metadata": {},
   "source": [
    "## Test conversion to 2-d structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b923925-3e3f-4b1b-bcc3-aa19cb065e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reproducible training\n",
    "set_for_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caea6448-878d-478f-8f72-6a340ccaafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model for 2-d structure\n",
    "\n",
    "\n",
    "def nn2():\n",
    "    model_input = Input(shape = (SEQUENCE_SIZE * EMBEDDING_SIZE,))   # altered for 2-d structure\n",
    "    model_input_unpack = tf.reshape(model_input, (-1, SEQUENCE_SIZE, EMBEDDING_SIZE))  # unpack to 3-d structure\n",
    "    model_dropout1 = SpatialDropout1D(0.2)(model_input_unpack)\n",
    "    model_lstm = LSTM(100, dropout = 0.2, recurrent_dropout = 0.2)(model_dropout1)\n",
    "    model_dense1 = Dense(50, activation = 'tanh')(model_lstm)\n",
    "    model_bn1 = BatchNormalization()(model_dense1)\n",
    "    model_dropout2 = Dropout(0.2)(model_bn1)\n",
    "    model_output = Dense(1, activation = 'sigmoid')(model_dropout2)\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = [AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c89d64-24a9-4523-b99a-9e8862ddedce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2-d model training\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 7s 49ms/step - loss: 0.7360 - auc: 0.4954\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.6593 - auc: 0.5064\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.6392 - auc: 0.5235\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.6348 - auc: 0.5230\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.6259 - auc: 0.5411: 0s - loss: 0.6258 - auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8ac88e850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = nn2()\n",
    "\n",
    "X_2d = X.reshape(-1, SEQUENCE_SIZE * EMBEDDING_SIZE)\n",
    "print('\\n2-d model training')\n",
    "model2.fit(X_2d, y, epochs=5, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907b2c1-4cbb-4deb-bfe4-141686cc41fb",
   "metadata": {},
   "source": [
    "## Compared learned parameters from the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850d741d-2a69-4f26-8ee3-efe8c3356621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare baseline model vs 2-d model\n",
      "False, max diff 0.0006649121642112732\n",
      "False, max diff 0.0010492801666259766\n",
      "False, max diff 0.0005425214767456055\n",
      "False, max diff 0.00015504658222198486\n",
      "False, max diff 0.0003531612455844879\n",
      "False, max diff 9.554624557495117e-05\n",
      "False, max diff 6.882846355438232e-05\n",
      "False, max diff 0.000373058021068573\n",
      "False, max diff 3.874674439430237e-05\n",
      "False, max diff 0.00011435151100158691\n",
      "False, max diff 6.034970283508301e-06\n"
     ]
    }
   ],
   "source": [
    "## Compare learned parameters\n",
    "print('compare baseline model vs 2-d model')\n",
    "for nn_parameter, nn2_parameter in zip(model.weights, model2.weights):\n",
    "    print(\n",
    "        f'{np.allclose(nn_parameter.numpy(), nn2_parameter.numpy())}, '\n",
    "        f'max diff {np.max(np.abs(nn_parameter.numpy() - nn2_parameter.numpy()))}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598cb3d-50cc-4f00-8a2e-405c5bb59a3a",
   "metadata": {},
   "source": [
    "## Test 2-d structure with scikeras.KerasClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19317413-9e7b-418c-83f7-33e536817268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329b6b6c-993f-4f06-84a7-2d0587b20b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for reproducible training\n",
    "set_for_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab19af44-db7b-47b7-adde-4ba3f9c69931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model for 2-d structure\n",
    "\n",
    "\n",
    "def nn_scikeras():\n",
    "    model_input = Input(shape = (SEQUENCE_SIZE * EMBEDDING_SIZE,))   # altered for 2-d structure\n",
    "    model_input_unpack = tf.reshape(model_input, (-1, SEQUENCE_SIZE, EMBEDDING_SIZE))  # unpack to 3-d structure\n",
    "    model_dropout1 = SpatialDropout1D(0.2)(model_input_unpack)\n",
    "    model_lstm = LSTM(100, dropout = 0.2, recurrent_dropout = 0.2)(model_dropout1)\n",
    "    model_dense1 = Dense(50, activation = 'tanh')(model_lstm)\n",
    "    model_bn1 = BatchNormalization()(model_dense1)\n",
    "    model_dropout2 = Dropout(0.2)(model_bn1)\n",
    "    model_output = Dense(1, activation = 'sigmoid')(model_dropout2)\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = [AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5888422-6bbf-4f6d-b8cf-193d0539c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scikeras model training\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 7s 51ms/step - loss: 0.7360 - auc: 0.4954\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.6593 - auc: 0.5064\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.6392 - auc: 0.5235\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.6348 - auc: 0.5230\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.6259 - auc: 0.5411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function nn_scikeras at 0x7fd89e65a5e0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=Adam\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scikeras = KerasClassifier(model=nn_scikeras, optimizer='Adam')\n",
    "\n",
    "X_2d = X.reshape(-1, SEQUENCE_SIZE * EMBEDDING_SIZE)\n",
    "print('\\nscikeras model training')\n",
    "model_scikeras.fit(X_2d, y, epochs=5, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37c822-18d0-439a-a0ea-3877493ad463",
   "metadata": {},
   "source": [
    "## Compared learned parameters from the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1530393c-d9a4-49f3-bd41-227403670dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare baseline model vs scikeras model\n",
      "False, max diff 0.0006649121642112732\n",
      "False, max diff 0.0010492801666259766\n",
      "False, max diff 0.0005425214767456055\n",
      "False, max diff 0.00015504658222198486\n",
      "False, max diff 0.0003531612455844879\n",
      "False, max diff 9.554624557495117e-05\n",
      "False, max diff 6.882846355438232e-05\n",
      "False, max diff 0.000373058021068573\n",
      "False, max diff 3.874674439430237e-05\n",
      "False, max diff 0.00011435151100158691\n",
      "False, max diff 6.034970283508301e-06\n"
     ]
    }
   ],
   "source": [
    "## Compare learned parameters\n",
    "print('compare baseline model vs scikeras model')\n",
    "for nn_parameter, scikeras_parameter in zip(model.weights, model_scikeras.model_.weights):\n",
    "       print(\n",
    "        f'{np.allclose(nn_parameter.numpy(), scikeras_parameter.numpy())}, '\n",
    "        f'max diff {np.max(np.abs(nn_parameter.numpy() - scikeras_parameter.numpy()))}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b87e20-9043-4653-b279-31766c5d055c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
